{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "visualize results for test image\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transforms as transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from models import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_size = 44\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.TenCrop(cut_size),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def fit_pred(path='images/1.jpg'):\n",
    "    raw_img = io.imread(path)\n",
    "    gray = rgb2gray(raw_img)\n",
    "    gray = resize(gray, (48,48), mode='symmetric').astype(np.uint8)\n",
    "\n",
    "    img = gray[:, :, np.newaxis]\n",
    "\n",
    "    img = np.concatenate((img, img, img), axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    inputs = transform_test(img)\n",
    "\n",
    "    class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "    net = VGG('VGG19')\n",
    "    checkpoint = torch.load(os.path.join('FER2013_VGG19', 'PrivateTest_model.t7'), map_location='cpu')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    # net.cuda()\n",
    "    net.eval()\n",
    "\n",
    "    ncrops, c, h, w = np.shape(inputs)\n",
    "\n",
    "    inputs = inputs.view(-1, c, h, w)\n",
    "    # inputs = inputs.cuda()\n",
    "    inputs = Variable(inputs, volatile=True)\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    outputs_avg = outputs.view(ncrops, -1).mean(0)  # avg over crops\n",
    "\n",
    "    score = F.softmax(outputs_avg)\n",
    "    _, predicted = torch.max(outputs_avg.data, 0)\n",
    "\n",
    "    predicted_emotion = class_names[int(predicted.cpu().numpy())]\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/list_attr_celeba.csv')[['image_id', 'Smiling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [08:32<00:00,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "results = []\n",
    "for im in tqdm(data.image_id[:N]):\n",
    "    results.append(fit_pred(path='../dataset/img_align_celeba/1000/{}'.format(im)))\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Emotion'] = ['Happy'  if i == 1 else 'Sad' for i in data.Smiling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angry', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "преобразуем результаты: если лицо распознано не как счастливое -- считаем, что оно без улыбки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_binary = ['Happy' if i == 'Happy' else 'Sad' for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_idx = np.where(np.array(data.Emotion[:N]) == 'Happy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.Emotion[:N] == np.array(results_binary)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5705882352941176"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['Emotion'][happy_idx] == np.array(results_binary)[happy_idx])/len(data['Emotion'][happy_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "traced_script_module = torch.jit.trace(net, inputs)\n",
    "\n",
    "traced_script_module.save(\"emotion_recognition.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как видно, есть куда расти в определении эмоций"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
